{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 109A/AC 209A/STAT 121A Data Science: Lab 10 (Solutions)\n",
    "**Harvard University**<br>\n",
    "**Fall 2016**<br>\n",
    "**Instructors: W. Pan, P. Protopapas, K. Rader**<br>\n",
    "**Due Date: ** Wednesday, November 9th, 2016 at 11:59pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.tree import DecisionTreeClassifier as DecisionTree\n",
    "from sklearn.ensemble import RandomForestClassifier as RandomForest\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Outcome of a Fund-raising Campaign, Revisited\n",
    "\n",
    "In this lab, we revisit a problem we tackled in Homework 4. \n",
    "\n",
    "You are provided a data set containing details of mail sent to 95,412 potential donors for a fund-raising campaign of a not-for-profit organization. This data set also contains the amount donated by each donor. The task is to build a model that can identify which donors to mail in order to expected maximize net contribution, given the cost of mailing a flyer or package is \\$7 per donor. \n",
    "\n",
    "In Homework 4, we used linear regression to first predict the amount that each individual will donate and then mailed a flyer to only those individuals that were predicted to donate more than \\$7.\n",
    "\n",
    "In this lab, we will cast this problem as a classification problem: we build a model to classify each individual as a mail-worthy donor (will likely donate more than \\$7) or a un-mail-worthy donor (will likely donate less than \\$7). Again, our goal is to maximize the expected net contribution.\n",
    "\n",
    "The data is contained in the file `dataset.txt`. Each row contains 376 attributes for a donor, followed by the donation amount.\n",
    "\n",
    "## Step 1: Clean and explore the data\n",
    "\n",
    "First let's read and explore the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OSOURCE</th>\n",
       "      <th>TCODE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>MAILCODE</th>\n",
       "      <th>NOEXCH</th>\n",
       "      <th>RECINHSE</th>\n",
       "      <th>RECP3</th>\n",
       "      <th>RECPGVG</th>\n",
       "      <th>RECSWEEP</th>\n",
       "      <th>MDMAUD</th>\n",
       "      <th>...</th>\n",
       "      <th>HPHONE_D</th>\n",
       "      <th>RFA_2R</th>\n",
       "      <th>RFA_2F</th>\n",
       "      <th>RFA_2A</th>\n",
       "      <th>MDMAUD_R</th>\n",
       "      <th>MDMAUD_F</th>\n",
       "      <th>MDMAUD_A</th>\n",
       "      <th>CLUSTER2</th>\n",
       "      <th>GEOCODE2</th>\n",
       "      <th>TARGET_D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BBK</td>\n",
       "      <td>2</td>\n",
       "      <td>MN</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SYN</td>\n",
       "      <td>0</td>\n",
       "      <td>TX</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>14</td>\n",
       "      <td>A</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DRK</td>\n",
       "      <td>0</td>\n",
       "      <td>IA</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>11</td>\n",
       "      <td>C</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BHG</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L01</td>\n",
       "      <td>1</td>\n",
       "      <td>GA</td>\n",
       "      <td>_</td>\n",
       "      <td>0</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>_</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>E</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>22</td>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 377 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  OSOURCE  TCODE STATE MAILCODE NOEXCH RECINHSE RECP3 RECPGVG RECSWEEP MDMAUD  \\\n",
       "0     BBK      2    MN        _      0        _     _       _        _   XXXX   \n",
       "1     SYN      0    TX        _      0        _     _       _        _   XXXX   \n",
       "2     DRK      0    IA        _      0        _     _       _        _   XXXX   \n",
       "3     BHG      0    CA        _      0        _     _       _        _   XXXX   \n",
       "4     L01      1    GA        _      0        _     _       _        _   XXXX   \n",
       "\n",
       "    ...    HPHONE_D RFA_2R RFA_2F RFA_2A MDMAUD_R MDMAUD_F MDMAUD_A CLUSTER2  \\\n",
       "0   ...           1      L      3      D        X        X        X        3   \n",
       "1   ...           1      L      3      D        X        X        X       14   \n",
       "2   ...           1      L      3      D        X        X        X       11   \n",
       "3   ...           0      L      2      F        X        X        X        2   \n",
       "4   ...           1      L      3      E        X        X        X       22   \n",
       "\n",
       "   GEOCODE2 TARGET_D  \n",
       "0         A        4  \n",
       "1         A        7  \n",
       "2         C        5  \n",
       "3         A       13  \n",
       "4         A       10  \n",
       "\n",
       "[5 rows x 377 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load and inspect the data\n",
    "data = pd.read_csv('datasets/dataset.txt', low_memory=False)  # low memory is set false for better type inference\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entries in the dataframe that read `'_'` are missing values. They should be replaced with NaN before you decide what to do with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OSOURCE</th>\n",
       "      <th>TCODE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>MAILCODE</th>\n",
       "      <th>NOEXCH</th>\n",
       "      <th>RECINHSE</th>\n",
       "      <th>RECP3</th>\n",
       "      <th>RECPGVG</th>\n",
       "      <th>RECSWEEP</th>\n",
       "      <th>MDMAUD</th>\n",
       "      <th>...</th>\n",
       "      <th>HPHONE_D</th>\n",
       "      <th>RFA_2R</th>\n",
       "      <th>RFA_2F</th>\n",
       "      <th>RFA_2A</th>\n",
       "      <th>MDMAUD_R</th>\n",
       "      <th>MDMAUD_F</th>\n",
       "      <th>MDMAUD_A</th>\n",
       "      <th>CLUSTER2</th>\n",
       "      <th>GEOCODE2</th>\n",
       "      <th>TARGET_D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BBK</td>\n",
       "      <td>2</td>\n",
       "      <td>MN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SYN</td>\n",
       "      <td>0</td>\n",
       "      <td>TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>14</td>\n",
       "      <td>A</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DRK</td>\n",
       "      <td>0</td>\n",
       "      <td>IA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>11</td>\n",
       "      <td>C</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BHG</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L01</td>\n",
       "      <td>1</td>\n",
       "      <td>GA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>E</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>22</td>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 377 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  OSOURCE  TCODE STATE MAILCODE NOEXCH RECINHSE RECP3 RECPGVG RECSWEEP MDMAUD  \\\n",
       "0     BBK      2    MN      NaN      0      NaN   NaN     NaN      NaN   XXXX   \n",
       "1     SYN      0    TX      NaN      0      NaN   NaN     NaN      NaN   XXXX   \n",
       "2     DRK      0    IA      NaN      0      NaN   NaN     NaN      NaN   XXXX   \n",
       "3     BHG      0    CA      NaN      0      NaN   NaN     NaN      NaN   XXXX   \n",
       "4     L01      1    GA      NaN      0      NaN   NaN     NaN      NaN   XXXX   \n",
       "\n",
       "    ...    HPHONE_D RFA_2R RFA_2F RFA_2A MDMAUD_R MDMAUD_F MDMAUD_A CLUSTER2  \\\n",
       "0   ...           1      L      3      D        X        X        X        3   \n",
       "1   ...           1      L      3      D        X        X        X       14   \n",
       "2   ...           1      L      3      D        X        X        X       11   \n",
       "3   ...           0      L      2      F        X        X        X        2   \n",
       "4   ...           1      L      3      E        X        X        X       22   \n",
       "\n",
       "   GEOCODE2 TARGET_D  \n",
       "0         A        4  \n",
       "1         A        7  \n",
       "2         C        5  \n",
       "3         A       13  \n",
       "4         A       10  \n",
       "\n",
       "[5 rows x 377 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Replace missing values with NaN\n",
    "data = data.replace('_', np.nan)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the NaN values appear only in a few columns. For the sake of expediency, we will simply drop the columns with missing values. **You might want to handle the missing data in a more sophisticated way**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TCODE</th>\n",
       "      <th>STATE</th>\n",
       "      <th>NOEXCH</th>\n",
       "      <th>MDMAUD</th>\n",
       "      <th>HIT</th>\n",
       "      <th>MALEMILI</th>\n",
       "      <th>MALEVET</th>\n",
       "      <th>VIETVETS</th>\n",
       "      <th>WWIIVETS</th>\n",
       "      <th>LOCALGOV</th>\n",
       "      <th>...</th>\n",
       "      <th>AVGGIFT</th>\n",
       "      <th>HPHONE_D</th>\n",
       "      <th>RFA_2R</th>\n",
       "      <th>RFA_2F</th>\n",
       "      <th>RFA_2A</th>\n",
       "      <th>MDMAUD_R</th>\n",
       "      <th>MDMAUD_F</th>\n",
       "      <th>MDMAUD_A</th>\n",
       "      <th>CLUSTER2</th>\n",
       "      <th>TARGET_D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>MN</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>4.066667</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>58</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>6.181818</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>IA</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>24</td>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>4.857143</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>L</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>GA</td>\n",
       "      <td>0</td>\n",
       "      <td>XXXX</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>3</td>\n",
       "      <td>E</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 316 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TCODE STATE NOEXCH MDMAUD  HIT  MALEMILI  MALEVET  VIETVETS  WWIIVETS  \\\n",
       "0      2    MN      0   XXXX   10         2       25        40        27   \n",
       "1      0    TX      0   XXXX    0         1       37        58        16   \n",
       "2      0    IA      0   XXXX    5         0       33        24        39   \n",
       "3      0    CA      0   XXXX    0         0       34        20        54   \n",
       "4      1    GA      0   XXXX   10         0       21        53         8   \n",
       "\n",
       "   LOCALGOV    ...       AVGGIFT  HPHONE_D  RFA_2R  RFA_2F  RFA_2A  MDMAUD_R  \\\n",
       "0        11    ...      4.066667         1       L       3       D         X   \n",
       "1         8    ...      6.181818         1       L       3       D         X   \n",
       "2         6    ...      4.857143         1       L       3       D         X   \n",
       "3         2    ...     11.000000         0       L       2       F         X   \n",
       "4         5    ...      9.400000         1       L       3       E         X   \n",
       "\n",
       "   MDMAUD_F  MDMAUD_A  CLUSTER2  TARGET_D  \n",
       "0         X         X         3         4  \n",
       "1         X         X        14         7  \n",
       "2         X         X        11         5  \n",
       "3         X         X         2        13  \n",
       "4         X         X        22        10  \n",
       "\n",
       "[5 rows x 316 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove columns with missing values\n",
    "\n",
    "complete_cols = [column for column in data.columns if len(data[column][data[column].isnull()]) == 0]\n",
    "        \n",
    "data = data[complete_cols]\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that some of the predictors are categorical and some are quantitative. We need to convert the real-valued predictor values into floating points and encode the categorical variables as integers (we will furthre convert the categorical variables into binary variable using one-hot-encoding). To decide which variables are quantitative and which are categorical, you need to interpret the meaning of each predictor and use your common sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Categoricals will be int or str (object), the rest float\n",
    "\n",
    "# List of columns to be converted to floating point\n",
    "to_float = ['HIT', 'MALEMILI', 'MALEVET', 'VIETVETS', 'WWIIVETS', 'LOCALGOV', 'STATEGOV', 'FEDGOV', 'NUMPRM12', \n",
    "           'CARDPM12', 'CARDPROM', 'NUMPROM', 'NGIFTALL', 'CARDGIFT']\n",
    "\n",
    "# Converted columns to floating point\n",
    "for feature_name in to_float:\n",
    "    data[feature_name] = data[feature_name].astype(float)\n",
    "\n",
    "# Columns between POP901 to AC2 should all be float\n",
    "index1 = data.columns.get_loc(\"POP901\")\n",
    "index2 = data.columns.get_loc(\"AC2\")\n",
    "\n",
    "for i in range(index1, index2 + 1):\n",
    "    data.iloc[:, i] = data.iloc[:, i].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Encode categorical variables\n",
    "def encode_categorical(array):\n",
    "    if not array.dtype == np.dtype('float64'):\n",
    "        return preprocessing.LabelEncoder().fit_transform(array) \n",
    "    else:\n",
    "        return array\n",
    "    \n",
    "# Categorical columns for use in one-hot encoder\n",
    "categorical = (data.dtypes.values != np.dtype('float64'))\n",
    "\n",
    "# Encode all labels\n",
    "data = data.apply(encode_categorical)\n",
    "\n",
    "# Get numpy array from data\n",
    "x = data.values[:, :-1]\n",
    "y = data.values[:, -1]\n",
    "\n",
    "# Apply one hot endcoing\n",
    "encoder = preprocessing.OneHotEncoder(categorical_features=categorical[:-1], sparse=False)  # Last value in mask is y\n",
    "x = encoder.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split our dataset into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train_val, y_test_val = train_test_split(x, y, test_size=0.6, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the response variable, amount donated, is a real-valued variable not a binary variable! We need to convert the amount donated into a binary value: 0 for under \\$7 and 1 for over \\$7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:  (3571, 397)\n",
      "test data:  (5357, 397)\n",
      "train class 0: 2025, train class 1: 1546\n",
      "test class 0: 3010, test class 1: 2347\n"
     ]
    }
   ],
   "source": [
    "#Threshold for class 0\n",
    "threshold = 7\n",
    "\n",
    "y_train = np.copy(y_train_val)\n",
    "y_test = np.copy(y_test_val)\n",
    "\n",
    "y_train[y_train_val > threshold] = 1\n",
    "y_train[y_train_val <= threshold] = 0\n",
    "\n",
    "y_test[y_test_val > threshold] = 1\n",
    "y_test[y_test_val <= threshold] = 0\n",
    "\n",
    "cost_per_donor = 7\n",
    "\n",
    "#Print some useful info for our test, train sets\n",
    "print 'train data: ', x_train.shape\n",
    "print 'test data: ', x_test.shape\n",
    "print 'train class 0: {}, train class 1: {}'.format(len(y_train[y_train == 0]), len(y_train[y_train == 1]))\n",
    "print 'test class 0: {}, test class 1: {}'.format(len(y_test[y_test == 0]), len(y_test[y_test == 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Establish the Baseline Models (for Sanity Check)\n",
    "\n",
    "What are the baseline models in this case? We can check off three basic models: \n",
    "\n",
    "1. a model that labels everything 1\n",
    "2. a model that labels everything 0\n",
    "3. a model that randomly guesses a label, 1 or 0\n",
    "\n",
    "Before implementing anything fancy, let's implement these baseline models and see how they do.\n",
    "\n",
    "**Note:** Again, think about accuracy in a **meaningful** way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function for computing the accuracy a given model on the entire test set, the accuracy on class 0 in the test set\n",
    "#and the accuracy on class 1\n",
    "score = lambda model, x_test, y_test: pd.Series([model.score(x_test, y_test), \n",
    "                                                 model.score(x_test[y_test==0], y_test[y_test==0]),\n",
    "                                                 model.score(x_test[y_test==1], y_test[y_test==1])],\n",
    "                                                index=['overall accuracy', 'accuracy on class 0', 'accuracy on class 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#A model that labels everything 1\n",
    "class Pos_model(object):\n",
    "    def predict(self, x):\n",
    "        return np.array([1] * len(x))\n",
    "    def score(self, x, y):\n",
    "        y_pred = self.predict(x)\n",
    "        y_err = y - y_pred\n",
    "        return len(y_err[y_err == 0]) * 1. / len(y_err)\n",
    "    \n",
    "#A model that labels everything 0\n",
    "class Neg_model(object):\n",
    "    def predict(self, x):\n",
    "        return np.array([0] * len(x))\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        y_pred = self.predict(x)\n",
    "        y_err = y - y_pred\n",
    "        return len(y_err[y_err == 0]) * 1. / len(y_err)\n",
    "\n",
    "\n",
    "#A model that randomly labels things\n",
    "class Random_model(object):\n",
    "    def predict(self, x):\n",
    "        return np.random.randint(0, 2, len(x))\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        y_pred = self.predict(x)\n",
    "        y_err = y - y_pred\n",
    "        return len(y_err[y_err == 0]) * 1. / len(y_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_model = Pos_model()\n",
    "pos_model_scores = score(pos_model, x_test, y_test)\n",
    "\n",
    "neg_model = Neg_model()\n",
    "neg_model_scores = score(neg_model, x_test, y_test)\n",
    "\n",
    "random_model = Random_model()\n",
    "random_model_scores = score(random_model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neg model</th>\n",
       "      <th>pos model</th>\n",
       "      <th>random model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>overall accuracy</th>\n",
       "      <td>0.561882</td>\n",
       "      <td>0.438118</td>\n",
       "      <td>0.493560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy on class 0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.519934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy on class 1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.497657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     neg model  pos model  random model\n",
       "overall accuracy      0.561882   0.438118      0.493560\n",
       "accuracy on class 0   1.000000   0.000000      0.519934\n",
       "accuracy on class 1   0.000000   1.000000      0.497657"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Score Dataframe\n",
    "score_df = pd.DataFrame({'pos model': pos_model_scores,\n",
    "                         'neg model': neg_model_scores,\n",
    "                         'random model': random_model_scores})\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Build Fancier Models\n",
    "\n",
    "Now that we have an idea of how baseline models perform, let's try to improve upon them with fancier classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unweighted log\n",
      "weighted log\n",
      "lda"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:688: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "qda\n",
      "tree\n",
      "rf\n"
     ]
    }
   ],
   "source": [
    "#Unweighted logistic regression\n",
    "unweighted_logistic = LogisticRegression()\n",
    "unweighted_logistic.fit(x_train, y_train)\n",
    "\n",
    "unweighted_log_scores = score(unweighted_logistic, x_test, y_test)\n",
    "print 'unweighted log'\n",
    "\n",
    "\n",
    "#Weighted logistic regression\n",
    "weighted_logistic = LogisticRegression(class_weight='balanced')\n",
    "weighted_logistic.fit(x_train, y_train)\n",
    "\n",
    "weighted_log_scores = score(weighted_logistic, x_test, y_test)\n",
    "print 'weighted log'\n",
    "\n",
    "#LDA\n",
    "lda = LDA()\n",
    "lda.fit(x_train, y_train)\n",
    "\n",
    "lda_scores = score(lda, x_test, y_test)\n",
    "print 'lda'\n",
    "\n",
    "#QDA\n",
    "qda = QDA()\n",
    "qda.fit(x_train, y_train)\n",
    "\n",
    "qda_scores = score(qda, x_test, y_test)\n",
    "print 'qda'\n",
    "\n",
    "#Decision Tree\n",
    "tree = DecisionTree(max_depth=6)\n",
    "tree.fit(x_train, y_train)\n",
    "\n",
    "tree_scores = score(tree, x_test, y_test)\n",
    "print 'tree'\n",
    "\n",
    "#Random Forest\n",
    "rf = RandomForest()\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "rf_scores = score(rf, x_test, y_test)\n",
    "\n",
    "print 'rf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lda</th>\n",
       "      <th>qda</th>\n",
       "      <th>rf</th>\n",
       "      <th>tree</th>\n",
       "      <th>unweighted logistic</th>\n",
       "      <th>weighted logistic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>overall accuracy</th>\n",
       "      <td>0.567855</td>\n",
       "      <td>0.538921</td>\n",
       "      <td>0.563375</td>\n",
       "      <td>0.566735</td>\n",
       "      <td>0.566175</td>\n",
       "      <td>0.564682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy on class 0</th>\n",
       "      <td>0.657475</td>\n",
       "      <td>0.562458</td>\n",
       "      <td>0.746844</td>\n",
       "      <td>0.748505</td>\n",
       "      <td>0.648505</td>\n",
       "      <td>0.537874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy on class 1</th>\n",
       "      <td>0.452919</td>\n",
       "      <td>0.508735</td>\n",
       "      <td>0.328078</td>\n",
       "      <td>0.333617</td>\n",
       "      <td>0.460588</td>\n",
       "      <td>0.599063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          lda       qda        rf      tree  \\\n",
       "overall accuracy     0.567855  0.538921  0.563375  0.566735   \n",
       "accuracy on class 0  0.657475  0.562458  0.746844  0.748505   \n",
       "accuracy on class 1  0.452919  0.508735  0.328078  0.333617   \n",
       "\n",
       "                     unweighted logistic  weighted logistic  \n",
       "overall accuracy                0.566175           0.564682  \n",
       "accuracy on class 0             0.648505           0.537874  \n",
       "accuracy on class 1             0.460588           0.599063  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Score Dataframe\n",
    "score_df = pd.DataFrame({#'knn': knn_scores, \n",
    "                         'unweighted logistic': unweighted_log_scores,\n",
    "                         'weighted logistic': weighted_log_scores,\n",
    "                         'lda': lda_scores,\n",
    "                         'qda': qda_scores,\n",
    "                         'tree': tree_scores,\n",
    "                         'rf': rf_scores})\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So which model is better? Which out-performs our baseline models? What does \"better\" mean anyways? \n",
    "\n",
    "To perform meaningful model selection, we have to remember our task! We've been asked to create a classifier that will maximize expected net contribution! While accuracy is a helpful metric, it is not clear, by looking at these numbers, which model will generate a greater expected net contribution!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Meaningful Model Evaluation\n",
    "\n",
    "To meaningully assess the effecitveness of our models, we have to evaluate them according to the utility function that computes the expected net contribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#--------  expected_profit\n",
    "# A function that computes the expected net contribution generated from a mailing scheme based on\n",
    "# your classification of potential doners as mail-worthy or not mail-worthy\n",
    "# Input: \n",
    "#      y_true_val (the true amount donated by each individual)\n",
    "#      y_true (true class labels)\n",
    "#      y_pred (predicted class labels)\n",
    "# Returns: \n",
    "#      expected_profit (expected net contribution)\n",
    "\n",
    "def expected_profit(y_true_val, y_true, y_pred):\n",
    "    \n",
    "    profit = []\n",
    "    \n",
    "    for i in range(5000):\n",
    "    \n",
    "        sample = np.random.choice(len(y_true_val), len(y_true_val))\n",
    "\n",
    "        true_donations = y_true_val[sample]\n",
    "        true_labels = y_true[sample]\n",
    "        pred_labels = y_pred[sample]\n",
    "\n",
    "        pred_donors = pred_labels > 0\n",
    "\n",
    "        cost = (pred_donors).sum() * 7.\n",
    "\n",
    "        donations = true_donations[pred_donors].sum()\n",
    "\n",
    "        profit.append(donations - cost)\n",
    "        \n",
    "    expected_profit = np.mean(profit)\n",
    "    \n",
    "    return expected_profit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we implement a selection of classification models. You should try more (like KNN, SVM, logistic with polynomial decision boundaries etc.)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unweighted log\n",
      "weighted log\n",
      "lda\n",
      "qda\n",
      "tree\n",
      "rf\n",
      "pos baseline\n",
      "neg baseline\n",
      "rand baseline\n",
      "total possible profit\n"
     ]
    }
   ],
   "source": [
    "profits = []\n",
    "\n",
    "#Unweighted logistic regression\n",
    "y_pred = unweighted_logistic.predict(x_test)\n",
    "\n",
    "profits.append(expected_profit(y_test_val, y_test, y_pred))\n",
    "\n",
    "print 'unweighted log'\n",
    "\n",
    "#Weighted logistic regression\n",
    "y_pred = weighted_logistic.predict(x_test)\n",
    "\n",
    "profits.append(expected_profit(y_test_val, y_test, y_pred))\n",
    "\n",
    "print 'weighted log'\n",
    "\n",
    "#LDA\n",
    "y_pred = lda.predict(x_test)\n",
    "\n",
    "profits.append(expected_profit(y_test_val, y_test, y_pred))\n",
    "\n",
    "print 'lda'\n",
    "\n",
    "#QDA\n",
    "y_pred = qda.predict(x_test)\n",
    "\n",
    "profits.append(expected_profit(y_test_val, y_test, y_pred))\n",
    "\n",
    "print 'qda'\n",
    "\n",
    "#Decision Tree\n",
    "y_pred = tree.predict(x_test)\n",
    "\n",
    "profits.append(expected_profit(y_test_val, y_test, y_pred))\n",
    "\n",
    "print 'tree'\n",
    "\n",
    "#Random Forest\n",
    "y_pred = rf.predict(x_test)\n",
    "\n",
    "profits.append(expected_profit(y_test_val, y_test, y_pred))\n",
    "\n",
    "print 'rf'\n",
    "\n",
    "#Positive Baseline Model\n",
    "y_pred = pos_model.predict(x_test)\n",
    "\n",
    "profits.append(expected_profit(y_test_val, y_test, y_pred))\n",
    "\n",
    "print 'pos baseline'\n",
    "\n",
    "#Negative Baseline Model\n",
    "y_pred = neg_model.predict(x_test)\n",
    "\n",
    "profits.append(expected_profit(y_test_val, y_test, y_pred))\n",
    "\n",
    "print 'neg baseline'\n",
    "\n",
    "#Random Baseline Model\n",
    "y_pred = random_model.predict(x_test)\n",
    "\n",
    "profits.append(expected_profit(y_test_val, y_test, y_pred))\n",
    "\n",
    "print 'rand baseline'\n",
    "\n",
    "#Total possible profit (if all predictions are accurate)\n",
    "profits.append(expected_profit(y_test_val, y_test, y_test))\n",
    "\n",
    "print 'total possible profit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unweighted log</th>\n",
       "      <th>weighted log</th>\n",
       "      <th>lda</th>\n",
       "      <th>qda</th>\n",
       "      <th>tree</th>\n",
       "      <th>rf</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>random</th>\n",
       "      <th>max possible profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>net contribution</th>\n",
       "      <td>5414.2376</td>\n",
       "      <td>6868.6997</td>\n",
       "      <td>5098.57895</td>\n",
       "      <td>5337.559</td>\n",
       "      <td>3273.21105</td>\n",
       "      <td>3282.83162</td>\n",
       "      <td>8145.186588</td>\n",
       "      <td>0</td>\n",
       "      <td>4055.71437</td>\n",
       "      <td>26349.864604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  unweighted log  weighted log         lda       qda  \\\n",
       "net contribution       5414.2376     6868.6997  5098.57895  5337.559   \n",
       "\n",
       "                        tree          rf          pos  neg      random  \\\n",
       "net contribution  3273.21105  3282.83162  8145.186588    0  4055.71437   \n",
       "\n",
       "                  max possible profit  \n",
       "net contribution         26349.864604  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Score Dataframe\n",
    "score_df = pd.DataFrame(data=np.array(profits).reshape((1, len(profits))), index=['net contribution'], columns=['unweighted log', 'weighted log', 'lda', 'qda', 'tree', 'rf', 'pos', 'neg', 'random', 'max possible profit'])\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did each model do - which is the best model? \n",
    "\n",
    "Compare the net contribution obtained from each model with the accuracy of each model. How is accuracy related to the net contribution? Is accuracy a good predictor of net contribution (meaning is accuracy a meaningful metric for evaluating our models)?\n",
    "\n",
    "What can we do to improve the performance of our models? \n",
    "\n",
    "**Hint:** Would tuning these models help? Consider, also, all the ensemble methods you've explored in the past two Homework sets: boosting and meta-learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Tuning to Maximize Net Contribution\n",
    "\n",
    "Take any model from the above, we can try to improve its performance (in terms of maximizing net contribution) by tuning its parameters to maximize the profit function. Here we demonstrate how to tune a decision tree. You should try the same for the rest of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth: 1\n",
      "depth: 2\n",
      "depth: 3\n",
      "depth: 4\n",
      "depth: 5\n",
      "depth: 6\n",
      "depth: 7\n",
      "depth: 8\n",
      "depth: 9\n",
      "depth: 10\n",
      "depth: 11\n",
      "depth: 12\n",
      "depth: 13\n",
      "depth: 14\n",
      "depth: 15\n",
      "depth: 16\n",
      "depth: 17\n",
      "depth: 18\n",
      "depth: 19\n",
      "profits for tuned tree with depth 18: 4838.32098\n"
     ]
    }
   ],
   "source": [
    "depths = range(1, 20)\n",
    "kf = KFold(len(x_train), n_folds=5)\n",
    "profits = []\n",
    "\n",
    "for depth in depths:\n",
    "    print 'depth:', depth\n",
    "    validation_profits = []\n",
    "    for train_index, test_index in kf:\n",
    "        x_validate_train, x_validate_test = x_train[train_index], x_train[test_index]\n",
    "        y_validate_train, y_validate_test = y_train[train_index], y_train[test_index]\n",
    "        \n",
    "        tree = DecisionTree(max_depth=depth)\n",
    "        tree.fit(x_validate_train, y_validate_train)\n",
    "        \n",
    "        y_pred = tree.predict(x_validate_test)\n",
    "        validation_profits.append(expected_profit(y_test_val[test_index], y_validate_test, y_pred))\n",
    "        \n",
    "    profits.append(np.mean(validation_profits))\n",
    "\n",
    "best_depth = np.argmax(profits) + 1\n",
    "\n",
    "tree = DecisionTree(max_depth=best_depth)\n",
    "tree.fit(x_train, y_train)\n",
    "y_pred = tree.predict(x_test)\n",
    "\n",
    "print 'profits for tuned tree with depth {}: {}'.format(best_depth, expected_profit(y_test_val, y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did the tuning improve the performance of our tree model?\n",
    "\n",
    "Now, consider what you can tune for weighted logistic regression (or SVM or random forest). Certainly, there is the regularization parameter $C$. In the above we just weighted each sample by the reciprocal of the class proportion (for the class that the sample belongs to). But can we weight the samples differently (using the `sample_weight` parameter in the `.fit()` function of the `sklearn` models)? How can you weight the samples to achieve maximum profit?\n",
    "\n",
    "**Hint:** think about how profit is related to accuracy in this application."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
